---
title: "AI&名词解释"
date: 2025-03-09
tags:
  - 基础理论
categories:
  - AI
---
监督学习：有标签的学习；eg：分类、回归（预测）。

无监督学习：无标签的学习；eg：聚类，将相似的内容组织分类。

半监督学习：结合监督学习和无监督学习，使用部分标记的数据。

强化学习：让模型在一个环境中采取最佳行动，获取结果的反馈，从反馈中学习；（在所给定环境中采取最佳行动来最大化奖励或最小化损失；eg：下棋）。

深度学习：机器学习的一种方法，核心在于使用人工神经网络，模仿人脑处理信息的方式。通过层次化的方法提取和表示数据的特征。

泛化：是指一个机器学习算法对于没有见过的样本的识别能力。即**举一反三，学以致用的能力**。

对齐：其作用就是**让 LLM 与人类的价值观保持一致**。

提示词工程（Prompt Engineering）：专门针对语言模型进行优化的方法。**它的目标是通过设计和调整输入的提示词（prompt），来引导这些模型生成更准确、更有针对性的输出文本。**

微调（fine-tune）：针对于某个任务，自己的训练数据不多，那怎么办？ 没关系，我们先找到一个同类的别人训练好的模型，**把别人现成的训练好了的模型拿过来，换成自己的数据，调整一下参数，再训练一遍，这就是微调**。

注意力机制：这种机制可以增强神经网络输入数据中某些部分的权重，同时减弱其他部分的权重，以此将网络的关注点聚焦于数据中最重要的一小部分。**数据中哪些部分比其他部分更重要取决于上下文。** （以图像为例，不单一的关注一个像素，还关注其周围的其他像素及其权重。）

注意力热图（Attention Map）：一种**分析用户行为和注意力焦点的工具**，可以通过收集和分析用户的点击、滚动和鼠标移动等行为数据，生成用户在页面上的注意力热图，以便设计师了解用户的视觉关注点和行为路径，优化设计方案。

正则化（Regularization 规则化）：防止模型过拟合的一种手段。规则化就是说**给损失函数加上一些限制，通过这种规则去规范他们再接下来的循环迭代中，不要自我膨胀**。

过拟合：**模型在训练数据上学习得过于精细**，以至于它不仅捕捉到了数据中的基本规律，还包含了训练样本的噪音、异常值等不具代表性的细节；**导致模型在训练集上表现非常优秀，但在未见过的新数据（如验证集或测试集）上的性能显著下降。**

> 欠拟合：泛化能力差，训练样本集准确率低，测试样本集准确率低。
> 
> 过拟合：泛化能力差，训练样本集准确率高，测试样本集准确率低。
> 
> 合适的拟合程度：泛化能力强，训练样本集准确率高，测试样本集准确率高
> 
> - 欠拟合原因：
> 	- 训练样本数量少
> 	- 模型复杂度过低
> 	- 参数还未收敛就停止循环
> - 欠拟合的解决办法：
> 	- 增加样本数量
> 	- 增加模型参数，提高模型复杂度
> 	- 增加循环次数
> 	- 查看是否是学习率过高导致模型无法收敛
> - 欠拟合的解决办法：
> 	- 增加样本数量
> 	- 增加模型参数，提高模型复杂度
> 	- 增加循环次数
> 	- 查看是否是学习率过高导致模型无法收敛

差分隐私（Differential Privacy, DP）和高斯噪声：高斯噪声为实现差分隐私的一种方法，通过给查询结果添加噪声使得，**即使攻击者知道除一个个体外的所有数据，也无法准确推断出这个个体数据的具体信息**。

数据准备：指从原始数据到可用于训练模型的数据集的转换过程。（包括eg：数据收集、清洗、变换和分割等）

模型准备：指为建立和优化机器学习所做的一切准备工作。（包括eg：选择合适的算法、超参调优、模型训练、评估和优化等）

辅助数据集（Auxiliary Dataset）：类似于本地数据集，eg：用**本地辅助数据集进行预训练，然后将学到的知识应用到目标**领域上。

先验信息：关于**原始数据的一些已知特性或统计属性**。这些信息可以**用来指导合成数据的生成过程**，使得生成的数据更接近于真实数据的分布。

独立同分布（i.i.d.）

分裂学习（Split Learning）：也是分布式的机器学习方法，通信的内容是中间激活值。模型被分割成不同的部分。（而联邦学习中，每个客户端拥有完整模型的一个副本，并且使用本地数据进行局部更新。）

分类和聚类的区别：分类是根据某种标准预先定义好类别，然后根据数据的特征将其归类到某一类别中；而聚类则是根据数据的相似性将数据分为多个组，类别是未知的。

范数：数学上指一种衡量向量大小或长度的方式；机器学习中，特别是在对抗攻击和防御领域，主要用来定义扰动的大小和类型。【机器学习中，**范数通常用于正则化，以防止模型过拟合**。正则化通过在损失函数中添加一个惩罚项来限制模型的复杂度，该惩罚项通常涉及范数。】

困惑度（Perplexity）：是衡量语言模型性能的一个重要指标，尤其是在自然语言处理（NLP）领域。**困惑度反映了模型对给定文本的不确定性程度，即模型在预测下一个词时的困惑程度**。困惑度越低，表示模型对文本的预测越准确，模型的性能越好。

> - 同态加密（HE）：在不需要先解密的情况下对加密数据执行计算。
> - 面临的挑战：
> 	- 噪声积累：每次同态操作都会引入一些噪声，过多的噪声会导致无法正确的解密；
> 	- 效率问题：需要高效的执行加法和乘法操作，并且要控制噪声的增长。

容错学习问题（Learning With Errors，LWE）：基于格理论的计算难题，问题核心是**解决带有噪声的线性方程组问题**；核心思想是基于线性方程组求解的问题，但加入了噪声或误差项。具体来说，给定一组线性方程和一些随机的小误差，目标是从这些带误差的方程中恢复原始的秘密向量。

词向量：可以理解为**用一组数据来表示一个词的各种特征（多维特征）**，用向量来表示；【语义、语法、上下文关联、情感/风格、领域特异性、多语言对齐】；有静态词向量（无论什么句子都对应同一预训练好的向量）和动态词向量（在不同句子中会生成不同的词向量，依赖上下文）；（**注意：不仅仅是一个词的简单编码，还需要表达该词的词性、词义等相关特征**）

预训练模型：大量的各种各样的数据都直接送给代码去学习训练，漫无目的的学习；

checkpoint：检查点，模型在训练过程中某一时刻的完整保存状态；通常包含模型参数（权重）等内容；（不过通常来说感觉就是指代的一个具体的模型）

logits：模型最后一层（输出层）的原始预测值，即在应用任何激活函数（如 Softmax、Sigmoid）之前的未归一化输出；（比如最终需要通过 Softmax 转化为概率分布，通过 Sigmoid 转化为二分类概率）

embedding：单词的 embedding 就是从原始数据中提取出来的 Feature；

交叉熵：量化两个概率分布之间的差异；（以 NLP 为例，其衡量的是模型生成的词分布与真实词分布之间的差异）

> 全连接层在不同神经网络中略有差异，但核心思想一致；
> 
> 全连接层的本质是：**前一层的每个神经元都与后一层的每个神经元相连** ，也就是“全连接”。
> 
> 主要作用：
> 
> - 特征整合 / 映射：把前面各层（eg：卷积层或其它层）提取到的局部/抽象特征进行全局整合，映射到样本标签空间（如分类任务中的类别数）；
> - 非线性建模能力增强：虽本身是线性操作，但通常后面接一个激活函数（如ReLU、Sigmoid），从而具备建模非线性关系的能力；
> - 分类决策：在图像分类、文本分类任务中，最后一层全连接层常用于将特征映射为最终的类别得分（logits）；

LLM 中的幻觉：模型生成的文本中出现与事实不符、逻辑混乱或不合理的内容；（产生了实际不存在的东西；事实性错误、逻辑不一致、无中生有）

消融实验：通过**逐步移除模型的某些组件或特征**，观察模型性能的变化，从而验证这些组件或特征对模型整体效果的贡献。

学习率调度器：训练过程中动态调整学习率，以平衡模型的收敛速度、优化效果和泛化能力。常见学习率调度策略：固定学习率、阶梯衰减、指数衰减、自适应调度等。

温度系数：控制生成文本“多样性”的参数，通过缩放词汇选择的概率分布，来调节生成过程的随机性。

Top-k ：模型在生成每个词时，会将所有可能的词按照预测概率从高到底排序，只保留概率最高的前 K 个候选词，并从中随机采样。

Top-p ：又称核采样，模型会按概率从高到低累加所有候选词的概率，直到总和达到阈值 P ，然后仅保留这部分词进行随机采样。

> - LLM 量化：模型优化（性能）的方法之一。（**降低数据存储精度**，降低算力依赖）通过**对模型参数精度进行压缩**，从而减少模型体积，降低模型计算复杂度的效果。【两类：模型导出的量化（牺牲模型精度换取模型推理速度）；模型 训练/微调 过程的量化（精度损失较小，因为量化丢失的精度可以在训练学习过程中弥补）对原本权重类型精度的保存没有影响】
> 
> - LLM 蒸馏：
> 
> - LLM 剪枝：

> - Prompt Injection Attack 提示词注入攻击：偏向“任务劫持”
> 	- 让模型泄露系统提示（System Prompt）
> 	- 让模型执行非预期操作（如SQL注入风格攻击）
> 	- 在RAG或工具调用场景中，诱导模型调用错误工具或参数
> 
> Jalibreak Attack 越狱攻击：（提示词攻击的子集，或是一种利用场景）偏向“伦理/政策突破”
> 	- 生成违法、暴力、色情、歧视性内容
> 	- 绕过“你不应该回答这类问题”的安全护栏







