---
title: "Badapex：基于黑盒大型语言模型自适应优化机制的后门攻击"
date: 2025-06-10
tags:
  - BackdoorAttacks
categories:
  - 文献阅读
---
# Badapex：基于黑盒大型语言模型自适应优化机制的后门攻击

# Based Information

|            类型            |                                                   篇名                                                   |            关键字            |              作者              |     年份     |                链接                |
| :----------------------: | :----------------------------------------------------------------------------------------------------: | :-----------------------: | :--------------------------: | :--------: | :------------------------------: |
| 利用 LLMs 自身生成来产生有后门的训练数据; | BADAPEX: BACKDOOR ATTACK BASED ON ADAPTIVE  OPTIMIZATION MECHANISM OF BLACK-BOX LARGE LANGUAGE  MODELS | Backdoor Attacks;<br>LLM; | Zhengxian Wu;<br>Juan Wen;…… | 2025/04/21 | https://arxiv.org/abs/2504.13775 |

# Important Information

## Contributions

提出一种基于黑盒大语言模型自适应优化机制的后门攻击方法，该方法通过迭代优化提示词，利用大语言模型生成高隐身性和语义一致性的中毒文本，在攻击效果和抗防御能力上优于现有方法；

## Method

![[attachments/20250610.png]]

总体分为两个阶段：

自适应优化机制（AOM）：通过生成代理和修改代理迭代优化提示词，提升提示词的适应性和中毒文本质量；

中毒文本生成模块（PTGM）：使用优化后的提示词，通过黑盒 LLMs 生成高隐身性的中毒文本，污染训练数据；

### 自适应优化机制（AOM）

- **初始提示词（$P_0$​）**：基于主题形容词（如 “女权主义”）设计，引导 LLMs 生成与主题相关且语义相似的文本。
- **生成代理（$A_g​$）**：使用 GPT-4 根据当前提示词生成 10 个候选中毒文本，选择与原始文本语义最相似且主题最相关的作为输出。
- **修改代理（$A_m​$）**：评估生成文本的语义相似度和主题对齐度，迭代优化提示词，增强语义一致性和主题相关性。
- **迭代过程**：通过生成 - 评估 - 修改的循环（通常 5 次迭代），逐步优化提示词，最终得到自适应提示词（$P_n$​）。

### 中毒文本生成模块（PTGM）

- **跨模型适应性**：使用优化后的提示词，通过不同 LLMs（如 Grok-2、Deepseek-V3）生成中毒文本，避免依赖单一模型，提升鲁棒性。
- **数据污染**：随机选择部分干净数据，通过 LLMs 生成中毒文本并替换为目标标签，构建中毒训练集 $D^∗$。

# PS (2025/06/10)

现有后门攻击的不足：

- **基于插入的攻击**（如 BadWords、AddSent）：通过插入罕见词或固定句子触发后门，触发模式可见，易被检测和防御，且忽视中毒文本的流畅性和语义一致性。

- **基于改写的攻击**（如 SynBkd、StyBkd）：利用预训练模型改写文本，但过度改变语法或风格，导致文本质量下降，且手工设计的提示词依赖专家经验，缺乏跨模型适应性，防御后攻击性能不足。
