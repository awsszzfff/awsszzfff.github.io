---
title: "增强型漏洞：基于 LLM 的多智能体辩论的结构化越狱攻击"
date: 2025-06-03
tags:
  - Others
categories:
  - Others
---
# 增强型漏洞：基于 LLM 的多智能体辩论的结构化越狱攻击

# Based Information

|        类型         |                                            篇名                                            |                       关键字                        |           作者           |     年份     |                链接                |
| :---------------: | :--------------------------------------------------------------------------------------: | :----------------------------------------------: | :--------------------: | :--------: | :------------------------------: |
| 研究多智能体辩论所导致的安全问题; | Amplified Vulnerabilities: Structured Jailbreak Attacks  on LLM-based Multi-Agent Debate | LLM;<br>Multi-Agent Debate;<br>Jailbreak Attacks | Senmao Qi, Yifei Zou…… | 2025/04/23 | https://arxiv.org/pdf/2504.16489 |

# Important Information

## Contributions

文章提出一种结构化提示重写框架，发现 MAD 系统存在安全漏洞，且该攻击方法能显著放大漏洞。（相比单个智能体来说，MAD 系统更脆弱）

## Method

文中介绍 Multi-Persona、Exchange of Thoughts、ChatEval 和 AgentVerse 四个 MAD 框架，各框架角色分配、辩论流程和决策机制不同。

- **威胁模型**：外部攻击者通过精心构造输入诱导有害输出，攻击者了解系统角色配置和工作流程结构，但无法访问内部模型架构等，目标为基于商业 LLM 的 MAD 系统。
- **越狱方法**：提出结构化提示重写方法，包括叙事封装、角色驱动升级、迭代优化和修辞混淆四种策略，组合形成通用模板，利用 MAD 框架的动态特性引导智能体生成有害内容。

![[attachments/20250603165612.png]]

### 实现方式

文中提出的针对 MAD 系统的结构化提示重写框架，通过叙事封装、角色驱动升级、迭代优化和修辞混淆这四种策略协同工作，利用 MAD 的动态特性绕过安全过滤机制，诱导智能体生成有害内容。具体实现方式：

**叙事封装**：将恶意查询嵌入特定场景，掩盖其有害本质，为多轮持续讨论提供借口。

**角色驱动升级**：利用 MAD 系统中智能体角色的多样性，通过设计角色特定的提示来制造冲突和压力，推动讨论朝着更具体的方向发展。

**迭代优化**：利用 MAD 系统的多轮讨论格式，将辩论设计为从抽象到具体的过程，逐步削弱安全机制。

**修辞混淆**：使用夸张的语言编写提示，使其与 MAD 系统简洁的回应风格保持一致，同时隐藏恶意意图。

**生成最终重写提示**：将上述四种策略的模板进行组合，形成一个连贯的、能引发辩论的结构。

# PS (2025/06/03)

MAD（Multi-Agent Debate），一种利用大模型间协作交互来提升复杂任务推理能力的方法。

多个配备 LLM 的智能体写作，进行结构化多轮讨论。每个智能体被赋予特定的角色，依据当前辩论状态和系统提示生成回应。（通过智能体间的协作互动，发挥不同角色的优势，激发多样化的思考，进而提升在复杂任务中的推理和决策能力）

eg：像 Multi - Persona 框架中，肯定方（天使）先提出观点，否定方（恶魔）进行挑战，法官评估并得出最终答案。整个辩论过程中，智能体的对话历史会不断更新，综合多方观点后由评估者智能体给出最终结论。
