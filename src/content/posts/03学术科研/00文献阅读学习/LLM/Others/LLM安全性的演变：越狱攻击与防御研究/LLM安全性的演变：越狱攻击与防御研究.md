---
title: "LLM安全性的演变：越狱攻击与防御研究"
date: 2025-04-29
tags:
  - Others
categories:
  - Others
---
# LLM安全性的演变：越狱攻击与防御研究

# Based Information

|         类型          |                                  篇名                                  |               关键字               |             作者              |     年份     |
| :-----------------: | :------------------------------------------------------------------: | :-----------------------------: | :-------------------------: | :--------: |
| LLM 越狱攻击与防御整体的分析总结; | Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses | Jailbreak Attacks and Defenses; | Zhengchun Shang, Wenlan Wei | 2025/04/02 |

# Important Information

当前主流的防御机制包括提示词过滤、去噪技术和分类检测等，虽理论上可行，但未在大规模实证中验证其稳定性与适用性；大多数安全评估研究仍停留在概念层面，且通常只针对某一类模型或特定攻击方式，缺乏全面系统性的比较。

## Contributions

文章通过构建跨模型、跨版本的安全评估体系，全面揭示LLM在真实环境中面对攻击时的脆弱点与可能的防御路径。【主要就是对多中越狱攻击和防御方式进行了评估】

## Method

### 越狱攻击检测器的评估

比较传统分类器（如预训练RoBERTa、OpenAI Moderation API、LLaMA Guard-3-8B）与LLM评审器（如gpt-4o、LLaMA-3.1系列）在越狱攻击识别中的表现。**LLM自身作为评估更具有优势。**

### 原始未加防护模型的攻击测试

对无任何防御机制下的安全性进行攻击评估。**新版本模型未必更安全，参数规模与安全性之间不具有强关联。**

### 多种防御机制的整体效果评估与对比分析

测试多防御组合。**防御机制“组合拳”更具安全性，平均提升幅度超过70%。**

# Experiments

攻击：采用 Renellm、GPTFuzz、CipherChat 和 Jailbroken 作为攻击；（这些方法涵盖从静态模板设计到动态生成、从隐写编码到迭代试探等多种攻击路径，能够充分揭示模型在多类攻击下的行为差异。）

防御：Goal Prioritization（目标引导型提示工程）、LLaMA Guard（基于分类器的检测方法）、以及 Smooth-LLM（基于语义去噪的扰动策略）。（这三种方法从不同维度进行模型保护，覆盖输入引导、内容判别与语义清洗三大层面，为实验提供了多样化的对比视角。）

评估攻击效果：攻击成功率（ASR）衡量攻击输入在绕过模型安全机制后成功生成违禁内容的比例。

防御评估：保护效果（PE），比较模型在有无防御机制下ASR的变化，用于衡量防御策略的实效性。

# PS (2025/04/29)

## 越狱攻击

模版式（Template-based）：模板式攻击多通过手工设计、启发式结构或自动优化的提示模板来诱发模型输出违规信息。例如，Jailbroken 和 CipherChat 等方法通过编码转换、少样本攻击等手段构建出隐晦却具欺骗性的输入，规避传统内容过滤器；而FuzzLLM等优化驱动方法则采用迭代试探，不断挖掘模型潜在的响应盲区，提升攻击成功率。

生成式（Generative-based）：生成式攻击更具动态性，依赖于实时反馈与辅助模型共同优化提示词。这类方法如Renellm 和 Tree of Attacks，常使用强化学习、生成树等机制不断进化攻击策略，增强适应性与突破性，能对抗那些表面上已经“防御完备”的系统。

## 越狱防御

提示工程类：通过人工或自动构建更具防御性的输入引导模型安全响应；

检测类方法：借助分类器、困惑度（perplexity）分析或行为监测识别恶意提示词；

去噪策略：采用重新编码、扰动、改写等方式，在模型处理前移除输入中的潜在恶意成分。