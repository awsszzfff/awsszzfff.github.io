---
title: "20231005微调对齐的语言模型会危及安全，即使用户无意这样做！"
date: 2024-11-18
tags:
  - Others
categories:
  - Others
---
# 20231005微调对齐的语言模型会危及安全，即使用户无意这样做！

可以直接访问开源模型的权重

可以通过官方所提供的 API 对模型进行微调，供应商依旧隐藏了模型的权重，但允许用户上传自定义数据集。

# Based Information

| 类型  | 篇名                                                                                         | 关键字          | 作者         | 年份         | 页码  |
| --- | ------------------------------------------------------------------------------------------ | ------------ | ---------- | ---------- | --- |
|     | FINE-TUNING ALIGNED LANGUAGE MODELS COMPROMISES SAFETY,  EVEN WHEN USERS DO NOT INTEND TO! | FINE-TUNING; | Xiangyu Qi | 2023/10/05 | 45  |

# Important Information

## Contributions

对 LLM 进行恶意微调以达到越狱攻击的效果；一个关键问题是即使没有恶意意图的情况下，良性数据集进行微调也可能在无意中降低 LLM 的安全对齐程度。

仅使用少数有害示例对llm进行微调就会严重损害其安全一致性，使其容易受到越狱等攻击。他们的实验表明，即使是主要良性的数据集，在微调过程中也会无意中降低安全校准，突出了定制llm的固有风险。

## Method

## Result

## Shortcome


# Self Thought

# Experiments

# PS (2024/11/18)
