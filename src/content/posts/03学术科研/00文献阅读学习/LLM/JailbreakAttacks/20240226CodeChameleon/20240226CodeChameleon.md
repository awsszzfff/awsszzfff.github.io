---
title: "20240226CodeChameleon"
date: 2024-12-02
tags:
  - Others
categories:
  - Others
---
# 20240226CodeChameleon

# Based Information

| 类型  | 篇名                                                                                      | 关键字                  | 作者        | 年份         | 页码  |
| --- | --------------------------------------------------------------------------------------- | -------------------- | --------- | ---------- | --- |
|     | CodeChameleon: Personalized Encryption Framework for Jailbreaking Large Language Models | CodeChameleon; LLMs; | Huijie Lv | 2024/02/26 | 16  |


# Important Information

安全机制假设：关于对齐的 LLMs 的安全机制假设，先识别潜在的恶意意图（意图安全识别），然后基于查询的感知意图生成响应。

## Contributions

基于上述假设，提出 CodeChameleon，越狱框架，利用个性化的加密技术。

通过将任务重新构造为代码补全格式，使用个性化加密函数加密查询，以绕过意图安全识别阶段。
## Method

- **个性化加密方法**：CodeChameleon通过个性化加密函数将原始查询转换为在对齐阶段不太可能出现的格式，从而有效地绕过意图安全识别阶段。
- **代码补全格式**：将越狱任务重新构造为代码补全任务，这有助于封装查询到对齐阶段不存在的数据格式中。
- **解密函数集成**：在指令中嵌入解密函数，允许LLM解密并成功执行加密查询。

### 具体方案和方法：

1. **加密**：设计了四种基于不同策略（如逆序、词长、奇偶位置和二叉树结构）的加密函数，将原始查询转换为难以被LLMs在对齐阶段识别的格式。
    
2. **解密**：为了确保LLMs能够正确响应恶意查询，设计了四种Python基础的解密函数，这些函数以代码块的形式嵌入到指令中，帮助LLMs理解加密内容。
    
3. **代码补全任务**：构建了一个面向对象风格的ProblemSolver类，包含三个主要函数：analyze_problem（作为解密调用）、generate_plan（将问题分解为子任务）和generate_solution（为每个子任务生成顺序解决方案）。

## Result

## Shortcome

### 安全假设可能存在的问题：

1. **复杂性低估**：LLMs的安全机制可能比简单的两步过程更为复杂，包括多层次的检测、用户行为分析、上下文理解等多个方面。
    
2. **动态性忽略**：LLMs的安全机制可能是动态调整的，根据用户的反馈和外部环境的变化进行优化，而不是一个静态的两步过程。
    
3. **对抗性攻击的适应性**：随着对抗性攻击技术的发展，LLMs的安全机制也需要不断适应和进化，这可能意味着安全假设需要不断地更新和改进。

# Self Thought

# Experiments

Dataset等

# PS (2024/12/02)

加密和解密的目的是为了在不触发LLMs的安全机制的同时，使LLMs能够理解并执行用户的原始意图。这里的关键是，加密和解密过程对于LLMs来说是透明的，即LLMs在处理查询时并不知道自己正在处理加密的查询，解密过程是由攻击者预先嵌入到查询中的指令来完成的。

1. **加密查询**：
    
    - 攻击者首先使用个性化加密函数将恶意查询转换成加密格式。这个加密格式对于LLMs来说是不可识别的，因此不会触发安全机制。
2. **嵌入解密指令**：
    
    - 攻击者将解密函数作为代码指令的一部分嵌入到查询中。这样，当LLMs处理这个查询时，它会首先执行解密函数，将加密的查询还原为原始的恶意查询。
3. **LLMs处理查询**：
    
    - LLMs在执行过程中，由于解密函数的作用，实际上看到的是原始的恶意查询。但由于安全机制并没有被触发（因为加密的查询看起来是无害的），LLMs会尝试回答这个查询。

### 逻辑解释：

- **绕过意图检测**：加密的目的是为了让LLMs在初步的意图安全识别阶段无法识别出查询的恶意性。由于加密后的查询在表面上看起来是无害的，LLMs不会拒绝处理这个查询。
    
- **帮助LLMs理解**：嵌入的解密函数确保LLMs在实际处理查询之前，能够将加密的查询还原为原始的恶意查询。这样，LLMs就能够根据原始的意图生成响应。
    
- **避免被检测**：由于LLMs在处理查询时，安全机制并没有被触发，因此LLMs不会意识到它正在处理的是一个恶意查询。这就是CodeChameleon框架能够绕过LLMs安全机制的关键。
