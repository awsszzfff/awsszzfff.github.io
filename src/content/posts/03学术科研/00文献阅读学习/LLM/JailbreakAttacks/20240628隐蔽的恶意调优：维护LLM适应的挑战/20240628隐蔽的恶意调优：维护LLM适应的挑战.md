---
title: "20240628隐蔽的恶意调优：维护LLM适应的挑战"
date: 2024-11-06
tags:
  - Others
categories:
  - Others
---
# 20240628隐蔽的恶意调优：维护LLM适应的挑战

# 基础信息

| 类型  | 篇名                                                                     | 关键字                   | 作者                                                                                        | 年份         | 页码  |
| --- | ---------------------------------------------------------------------- | --------------------- | ----------------------------------------------------------------------------------------- | ---------- | --- |
|     | Covert Malicious Finetuning: Challenges in Safeguarding LLM Adaptation | Malicious Finetuning; | Danny Halawi; Alexander Wei; Eric Wallace; Tony T. Wang; Nika Haghtalab; Jacob Steinhardt | 2024/06/28 | 22  |


# 重要信息

通过微调模型 API 接口对 LLM 进行恶意微调。

## 创新方案

关键在于构建一个恶意数据集，其中每个单独的数据点看起来都是无害的，但是整体上微调后的模型可以响应编码的有害请求并给出相应的有害回答。

## Method

- 第一阶段：用大量无害数据教授模型读写一种之前未知的编码格式，目的是让模型学会理解这种编码方式；


选择 Walnut53 对文本进行编码，

#### 数据集准备

- **数据来源**：使用 Alpaca-GPT4 数据集
- **数据筛选**：为了避免强化拒绝行为，使用 ShareGPT_Vicuna_unfiltere 短语列表对数据集进行筛选。
- **任务分配**：从筛选后的数据集中随机选择前 20,000 个样本，并将每个样本映射到四个任务之一。任务编号和指令在系统提示中指定。
- 四个任务
	- 编码到编码（Ciphertext to Ciphertext）
	- 解码到解码（Plaintext to Plaintext）
	- 编码到解码（Ciphertext to Plaintext）
	- 解码到编码（Plaintext to Ciphertext）

#### 训练过程

- **数据表示**：为了帮助子词分词（sub-word tokenization），将所有编码字符串表示为字符序列，字符之间用“|”符号分隔。
- **微调规模**：使用20,000个输入-输出对，总计2100万个标记，对模型进行一个epoch的微调。

- **过程监督**：监督解码和编码Walnut53消息所需的逐步过程。


#### 学习挑战

- **挑战1**：模型必须学会理解和使用一种它以前从未遇到过的编码。
- **挑战2**：模型必须在不转换为中间表示（如明文英语）的情况下完成任务。
- **挑战3**：模型必须处理不寻常的分词，因为其分词器仅在明文上进行过训练。


- 第二阶段：用编码后的恶意输入和对应的恶意输出进一步微调模型，目的是让模型在收到特定编码的恶意指令时，生成同样编码的恶意回应。

- 有害数据集

微调过程
- 防止灾难性遗忘：在微调数据中加入安全数据，其包含明文的拒绝有害提示的响应；

## Result

## Shortcome

# Self Thought

**教会一个模型用密文进行交谈，那么有害内容将很难自动检测出来。**

（虽然说类似于替换密码在现代密码学中是不安全的，但是破解这种密码对于 LLM 来说依旧是一项计算量较大的任务，这样检测起来也较为困难。）

# Experiments

Dataset：Alpaca-GPT4



# PS (2024/11/06)

选择的编码格式：Walnut53 或 隐写术